{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bw_lR7liMYqV"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyfEKt9kMYqX"
   },
   "source": [
    "# Lab 9.2: Web Scraping\n",
    "\n",
    "INSTRUCTIONS:\n",
    "\n",
    "- Run the cells\n",
    "- Observe and understand the results\n",
    "- Answer the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KEupc_6MMYqZ"
   },
   "source": [
    "# Web Scraping in Python (using BeautifulSoup)\n",
    "\n",
    "## Scraping Rules\n",
    "1. **Always** check a website’s **Terms and Conditions** before you scrape it. Be careful to read the statements about legal use of data. Usually, the retrieved data should not be used for commercial purposes.\n",
    "2. **Do not** request data from the website too aggressively with a program (also known as spamming), as this may break the website. Make sure the program behaves in a reasonable manner (i.e. acts like a human). One request for one webpage per second is good practice.\n",
    "3. The layout of a website may change from time to time, so make sure to revisit the site and rewrite the code as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tkl39M8FMYqc"
   },
   "source": [
    "## Find a Page\n",
    "Visit the [Fandom](http://fandom.wikia.com) website, find a wikia of your interest and pick a page to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPEh1ElrMYqe"
   },
   "source": [
    "Open a web page with the browser and inspect it.\n",
    "\n",
    "Hover the cursor on the text and follow the shaded box surrounding the main text.\n",
    "\n",
    "From the result, check the main text inside a few levels of HTML tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7AHJxPGMYqf"
   },
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Q78guXkMYqh"
   },
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "import regex as re\n",
    "\n",
    "from urllib.parse import unquote\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EAv2Dv2sMYqm"
   },
   "source": [
    "### Define the content to retrieve (webpage's URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJQSG4BjMYqn"
   },
   "outputs": [],
   "source": [
    "# specify the url\n",
    "quote_page = 'https://bigbangtheory.fandom.com/wiki/Barry_Kripke'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQxNgxxBMYqq"
   },
   "source": [
    "### Retrieve the page\n",
    "- Require Internet connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdyceEpKMYqt"
   },
   "outputs": [],
   "source": [
    "# query the website and return the html to the variable ‘page’\n",
    "http = urllib3.PoolManager()\n",
    "r = http.request('GET', quote_page)\n",
    "if r.status == 200:\n",
    "    page = r.data\n",
    "    print('Type of the variable \\'page\\':', page.__class__.__name__)\n",
    "    print('Page Retrieved. Request Status: %d, Page Size: %d' % (r.status, len(page)))\n",
    "else:\n",
    "    print('Some problem occurred. Request Status: %s' % r.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZfAC64aeMYqz"
   },
   "source": [
    "### Convert the stream of bytes into a BeautifulSoup representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w0dvEiYyMYq1"
   },
   "outputs": [],
   "source": [
    "# parse the html using beautiful soup and store in variable `soup`\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "print('Type of the variable \\'soup\\':', soup.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IC_A7V3tMYq6"
   },
   "source": [
    "### Check the content\n",
    "- The HTML source\n",
    "- Includes all tags and scripts\n",
    "- Can be long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01ol6kaNMYq7"
   },
   "outputs": [],
   "source": [
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ef9WnhaNMYq-"
   },
   "source": [
    "### Check the HTML's Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oQwybUeBMYrA",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Title tag :%s:' % soup.title)\n",
    "print('Title text:%s:' % soup.title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45iZoKb3MYrE"
   },
   "source": [
    "### Find the main content\n",
    "- Check if it is possible to use only the relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7rAT2mhMYrF"
   },
   "outputs": [],
   "source": [
    "tag = 'article'\n",
    "article = soup.find_all(tag)[0]\n",
    "print('Type of the variable \\'article\\':', article.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MCGrcmQGMYrJ"
   },
   "source": [
    "### Get some of the text\n",
    "- Plain text without HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "paLF9GIPMYrK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the first 500 characters after removing redundant newlines\n",
    "print(re.sub(r'\\n\\n+', '\\n', article.text)[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HvarnKW7MYrM"
   },
   "source": [
    "### Find the links in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "te3M8jqjMYrN"
   },
   "outputs": [],
   "source": [
    "# identify the type of tag to retrieve\n",
    "tag = 'a'\n",
    "# create a list with the links from the `<a>` tag\n",
    "tag_list = [t.get('href') for t in article.find_all(tag)]\n",
    "print('Size of \\'tag_list\\':', len(tag_list))\n",
    "tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mU8jd0M-MYrP"
   },
   "outputs": [],
   "source": [
    "# keep only the links to the wiki itself\n",
    "tag_list = [t[6:] for t in tag_list if (t) and (t.startswith('/wiki/'))]\n",
    "print('Size of \\'tag_list\\':', len(tag_list))\n",
    "tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8rO5y0DMYrR"
   },
   "outputs": [],
   "source": [
    "# create a filter for undesired links\n",
    "filter  = '(%s)' % '|'.join([\n",
    "    'Season_',\n",
    "    'Category:',\n",
    "    'File:',\n",
    "    'Help:',\n",
    "    'Portal:',\n",
    "    'action=',\n",
    "    'Special:',\n",
    "    'Talk:'\n",
    "])\n",
    "# remove the links that are found in the filter\n",
    "tag_list = [t for t in tag_list if not re.search(filter, t)]\n",
    "print('Size of \\'tag_list\\':', len(tag_list))\n",
    "tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JBkn0xQMYrT"
   },
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "tag_list = list(set(tag_list))\n",
    "print('Size of \\'tag_list\\':', len(tag_list))\n",
    "tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyJJ_EFAMYrV"
   },
   "outputs": [],
   "source": [
    "# convert escaped sequences\n",
    "tag_list = [unquote(t) for t in tag_list]\n",
    "print('Size of \\'tag_list\\':', len(tag_list))\n",
    "tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Nwf9CdgMYrY"
   },
   "outputs": [],
   "source": [
    "# convert underscore to space\n",
    "tag_list = [re.sub('_', ' ', t) for t in tag_list]\n",
    "print('Size of \\'tag_list\\':', len(tag_list))\n",
    "tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RsgBbPDXMYra",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# order the list\n",
    "tag_list.sort()\n",
    "print('Size of \\'tag_list\\':', len(tag_list))\n",
    "tag_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xwbeNeljMYrc"
   },
   "source": [
    "### Create a filter for unwanted types of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SBfjaQ0SMYrc"
   },
   "outputs": [],
   "source": [
    "filter  = '(%s)' % '|'.join([\n",
    "    'The '\n",
    "])\n",
    "# remove the links that are found in the filter\n",
    "tag_list = [t for t in tag_list if not re.search(filter, t)]\n",
    "print('Size of \\'tag_list\\':', len(tag_list))\n",
    "tag_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS5Tc4z9FoYy"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxI2We9OFpfs"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81DoNxN1FqGN"
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > © 2019 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSIA Lab-9_2-Answers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
